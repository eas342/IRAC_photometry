{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import functions as func\n",
    "import matplotlib.pyplot as plt\n",
    "import pdb, glob, mpld3, time\n",
    "import mirpyidl as idl\n",
    "from tqdm import tqdm\n",
    "from astropy.io import fits, ascii\n",
    "from astropy.wcs import WCS\n",
    "from astropy import units as u\n",
    "from astropy.coordinates import SkyCoord\n",
    "from astropy.table import Table\n",
    "from mpld3 import plugins\n",
    "\n",
    "%matplotlib inline\n",
    "plt.rcParams[\"figure.figsize\"] = (10, 8)\n",
    "mpld3.enable_notebook()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**File name directory example:  \n",
    "bd +60 1753 all ch1 data: /data1/phot_cal/spitzer/bd601753/r*/ch1/bcd/*_bcd.fits**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "20"
      ]
     },
     "execution_count": 77,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# fnames = np.sort(glob.glob(raw_input('path to bcd files:')))\n",
    "fnames = np.sort(glob.glob('../bd_aor_test/r20966144/ch1/bcd/*_bcd.fits'))\n",
    "len(fnames)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Next two cells generates flux data with no systematics removed**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#Provide proper sky coordinates in hms\n",
    "# '18 02 30.7410086899 +58 37 38.157415821' for HD 165459\n",
    "# '17 24 52.2772360943 +60 25 50.780790994' for BD +60 1753\n",
    "\n",
    "# sky = SkyCoord(raw_input('Target coordinates in hms:'), unit=(u.hourangle, u.deg))\n",
    "sky = SkyCoord('17 24 52.2772360943 +60 25 50.780790994', unit=(u.hourangle, u.deg))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'20966144_0002_0001_4'"
      ]
     },
     "execution_count": 78,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Play with filenames to see what portion of the name you want in data table\n",
    "a,b = 44, 64\n",
    "fnames[5][a:b]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 20/20 [00:03<00:00,  5.58it/s]\n"
     ]
    }
   ],
   "source": [
    "#Issues list\n",
    "crd_conversion = []\n",
    "centroiding    = []\n",
    "bad_cen_guess  = []\n",
    "not_in_fov     = []\n",
    "\n",
    "data = Table(names = ('File#','ACenX', 'ACenY', 'FCenX', 'FCenY', 'Time[MJD]', 'Raw_Flux', 'Bkg_Flux', 'Res_Flux'), \n",
    "             dtype = ('S25', 'f8', 'f8', 'f8', 'f8', 'f8', 'f8', 'f8', 'f8'))\n",
    "\n",
    "\n",
    "for fn in tqdm(fnames):\n",
    "    \n",
    "    hdu    = fits.open(fn)\n",
    "    header = hdu[0].header\n",
    "    image  = hdu[0].data\n",
    "    hdu.close()\n",
    "\n",
    "    fnum = fn[a:b]\n",
    "    Time = header['MJD_OBS']\n",
    "\n",
    "    try:\n",
    "        w = WCS(header)\n",
    "        pix = sky.to_pixel(w)\n",
    "    except:\n",
    "        crd_conversion.append(fnum)\n",
    "        continue\n",
    "\n",
    "    if (pix[0]>0) & (pix[0]<256) & (pix[1]>0) & (pix[1]<256):\n",
    "\n",
    "        try:\n",
    "            cenX, cenY = func.gen_center_g2d(pix[0], pix[1], 7, 5, 4, 4, 0, image)\n",
    "        except:\n",
    "            centroiding.append(fnum)\n",
    "            continue\n",
    "        \n",
    "        if (np.abs(cenX - pix[0]) <= 2) & (np.abs(cenY-pix[1]) <= 2):\n",
    "            \n",
    "            try:\n",
    "                # Extracting raw flux\n",
    "                raw_flux, src_ap = func.photometry(image, [cenX], [cenY], rad = 10)\n",
    "\n",
    "                # Extrating a mean background flux\n",
    "                bkg, bkg_ap = func.photometry(image, [cenX], [cenY], shape = 'CircAnn', r_in = 12, r_out = 20)\n",
    "                bkg_mean = bkg/bkg_ap.area()\n",
    "                bkg_flux = bkg_mean*src_ap.area()\n",
    "\n",
    "                # Subtracting background\n",
    "                res_flux  = raw_flux - bkg_flux\n",
    "\n",
    "                data.add_row([fnum, pix[0], pix[1], cenX, cenY, Time, raw_flux, bkg_flux, res_flux])\n",
    "            \n",
    "            except:\n",
    "                continue\n",
    "            \n",
    "        else:\n",
    "            bad_cen_guess.append(fnum)\n",
    "            \n",
    "    else:\n",
    "        not_in_fov.append(fnum)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Run next cell if you want to save the data generated from previous cell  \n",
    "Uncomment the first 3 lines if you want to save the file names that are causing problems  \n",
    "Change file names if you don't want to overwrite**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "../data_for_idl/bd_r20966144_bcd.csv\n"
     ]
    }
   ],
   "source": [
    "#np.save('crd_conversion_issue_bd_ch1.npy', np.array(crd_conversion))\n",
    "#np.save('centroiding_issue_bd_ch1.npy', np.array(centroiding))\n",
    "#np.save('bad_cen_guess_bd_ch1.npy', np.array(bad_cen_guess))\n",
    "\n",
    "# n = '../data_for_idl/' + raw_input('filename:')\n",
    "n = '../data_for_idl/bd_r' + str(header['AORKEY']) + '_bcd.csv'\n",
    "ascii.write(data, n, delimiter = ',', overwrite = True)\n",
    "print n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Remove systematics using IDL code  \n",
    "Systematics removed through this process: Array location dependent correction, pixel phase correction, callibration factor**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```idl\n",
    "data  = read_csv('data_for_idl/xyz.csv') ;Use proper file path\n",
    "cenX  = data.field4                      ;Usually column 4 is the fitted cenX column of my generated table\n",
    "cenY  = data.field5                      ;Be careful about which column you are using\n",
    "oFlux = data.field9                      ;We use the residual flux column for observed flux\n",
    "\n",
    ";Now to calculate corrected flux\n",
    ";Make sure to have irac_aphot_corr_cryo.pro in the same folder\n",
    ";You might need to comple it using .compile irac_aphot_corr_cryo.pro command \n",
    "\n",
    "cFlux = IRAC_APHOT_CORR_CRYO(oFlux, cenX, cenY, 1)\n",
    "fname = 'idl_results/xyz.csv'\n",
    "write_csv, fname, cFlux, header = ['cFlux']\n",
    "\n",
    ";Useful commands:\n",
    ";help, data  (works with any array)\n",
    ";print, data \n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Use last systematics removed flux to remove another systematics: Aperture correction**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# corr_flux = ascii.read(raw_input('corrected flux file path:'))  \n",
    "corr_flux = ascii.read('../idl_results/bd_r20966144_bcd_res.csv')  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Find the aperture correction factor from the following link:\n",
    "# https://irsa.ipac.caltech.edu/data/SPITZER/docs/irac/iracinstrumenthandbook/27/\n",
    "#from the table at the end of that link, select your value accoring to your aperture size and channel\n",
    "\n",
    "ap_corr = 1.000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [],
   "source": [
    "#write the refined flux to the data table in a new column\n",
    "\n",
    "\"\"\"\n",
    "#Uncomment this section if you want to load a previously generated data file\n",
    "data = ascii.read(raw_input('data table file path:'))   \n",
    "#Otherwise, data generated in this notebook will be used\n",
    "\"\"\"\n",
    "\n",
    "data['Refined_Flux'] = np.array(corr_flux).astype('Float64')*ap_corr"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Go from MJy/Sr to Jy**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.1008549975617078e-08"
      ]
     },
     "execution_count": 82,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pixLen  = 1.221 #arcsec\n",
    "pixArea = pixLen**2 #arcsec^2\n",
    "\n",
    "# 1 rad = 206265\"\n",
    "# 1 sr = 1 rad^2 = (206265**2) arcsec^2\n",
    "pixArea = pixArea/(206265**2) #Steradian\n",
    "\n",
    "apRadius = 10 #pixel length\n",
    "apArea   = np.pi*(apRadius**2) #pixel area\n",
    "apArea   = apArea*pixArea #Steradian\n",
    "apArea"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [],
   "source": [
    "data['Raw_Flux'] *= (pixArea*(10**9)) #Multiply by apArea to get to MJy and by 10^9 to get to mJy\n",
    "data['Bkg_Flux'] *= (pixArea*(10**9))\n",
    "data['Res_Flux'] *= (pixArea*(10**9))\n",
    "data['Refined_Flux'] *= (pixArea*(10**9))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Run next cell if you want to save refined data with correct units to a csv file  \n",
    "To activate the cell, select it, press esc and then y  \n",
    "Change file names if you don't want to overwrite**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 235,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "file path:../bd_aor_test/r65464064_bcd.csv\n"
     ]
    }
   ],
   "source": [
    "# ascii.write(data, raw_input('file path:'), overwrite = True)\n",
    "ascii.write(data, '../bd_aor_test/r65217280_bcd.csv', overwrite = True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Optional Analysis\n",
    "To activate the cell, select it, press esc and then y**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(38.99355643687791, 0.40161428099055035, 1.0299503756234099)"
      ]
     },
     "execution_count": 86,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mean  = np.mean(data['Refined_Flux'])\n",
    "stdev = np.std(data['Refined_Flux'])\n",
    "mean, stdev, (stdev/mean)*100"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
